{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from tqdm import tqdm\n",
        "from datetime import datetime\n",
        "from sklearn.metrics import accuracy_score\n",
        "from classes import DataManager, PipelineFactory, my_example_topics\n",
        "\n",
        "start_time = datetime.now()\n",
        "\n",
        "NUM_TOPICS = 5\n",
        "NUM_DATA_POINTS = 1000\n",
        "pd.options.display.max_colwidth = 50\n",
        "\n",
        "# import data\n",
        "# df = pd.read_csv('/root/Sefaria-Project/ML/data/yishai_data.csv')[:NUM_DATA_POINTS]\n",
        "# df = pd.read_pickle('data/1k.pkl')\n",
        "# df = pd.read_pickle('data/full_df.pkl')[:NUM_DATA_POINTS]\n",
        "df = pd.read_pickle('data\\single_class_df.pkl')[:NUM_DATA_POINTS]\n",
        "\n",
        "# df = pd.read_pickle('data\\small_version_OHE_df.pkl')[:NUM_DATA_POINTS]\n",
        "\n",
        "# df.to_pickle('/root/Sefaria-Project/ML/data/1k.pkl')\n",
        "# df.set_index('Ref',\n",
        "#     drop=False,\n",
        "#     inplace=True)\n",
        "\n",
        "# init data manager class\n",
        "data_manager = DataManager(raw = df, num_topics = NUM_TOPICS)\n",
        "\n",
        "# split train and test data\n",
        "train, test = data_manager.get_train_and_test()\n",
        "\n",
        "# select relevant input, e.g. words in passage\n",
        "X_train = train.En\n",
        "X_test = test.En\n",
        "\n",
        "# MY_INDEX = 1\n",
        "MY_INDEX_LIST = range(2)\n",
        "for MY_INDEX in MY_INDEX_LIST:\n",
        "    print('\\nACTUAL PASSAGE:',X_test.iloc[MY_INDEX])\n",
        "    print('\\nACTUAL TOPICS:',\n",
        "    # test.iloc[MY_INDEX]\n",
        "    # test.columns[(test == 1).iloc[MY_INDEX]]\n",
        "    (test.iloc[MY_INDEX] == 1).idxmax(axis=1)\n",
        "    )\n",
        "\n",
        "finish_time = datetime.now()\n",
        "\n",
        "total_time = finish_time - start_time\n",
        "print('\\n>>> Total runtime:',total_time)\n",
        "sys.exit()\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer(strip_accents='unicode', analyzer='word', ngram_range=(1,3), norm='l2')\n",
        "vectorizer.fit(X_train)\n",
        "# vectorizer.fit(test_text)\n",
        "\n",
        "x_train = vectorizer.transform(X_train)\n",
        "y_train = train.drop(labels = ['Ref','En','Topics'], axis=1)\n",
        "\n",
        "x_test = vectorizer.transform(X_test)\n",
        "y_test = test.drop(labels = ['Ref','En','Topics'], axis=1)\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Using pipeline for applying logistic regression and one vs rest classifier\n",
        "LogReg_pipeline = Pipeline([\n",
        "                ('clf', OneVsRestClassifier(LogisticRegression(solver='sag'), n_jobs=-1)),\n",
        "            ])\n",
        "\n",
        "categories = my_example_topics\n",
        "\n",
        "\n",
        "for category in categories:\n",
        "    print('\\n**Processing {} comments...**'.format(category))\n",
        "    \n",
        "    # Training logistic regression model on train data\n",
        "    LogReg_pipeline.fit(x_train, train[category])\n",
        "    \n",
        "    # calculating test accuracy\n",
        "    prediction = LogReg_pipeline.predict(x_test)\n",
        "    print('Test accuracy is {}'.format(accuracy_score(test[category], prediction)))\n",
        "\n",
        "\n",
        "sys.exit()\n",
        "\n",
        "# get shape\n",
        "print('\\ntraining passages',X_train.shape[0])\n",
        "print('testing passages',X_test.shape[0])\n",
        "\n",
        "# get most poular topics\n",
        "top_topics_df = data_manager.get_top_topics()\n",
        "top_topics_list = list(top_topics_df['topic']) # + ['ammon']\n",
        "print(top_topics_list)\n",
        "# top_topics = 'laws-of-judges-and-courts judgements1 laws-of-setting-the-months-and-leap-years sanhedrin'.split()\n",
        "# top_topics = 'ammon'.split()\n",
        "# top_topics = 'fate-of-the-nations-of-the-world punishment'.split()\n",
        "\n",
        "\n",
        "# select a model: Linear SVC, Multinimial Naive-Bayes, or Logistic Regression\n",
        "pipeline = PipelineFactory(\n",
        "    # 'LinSVC'\n",
        "    'LogReg'\n",
        "    # 'MultNB' # seems buggy! predicts all zeroes!\n",
        "    ).get_pipeline()\n",
        "\n",
        "\n",
        "# init\n",
        "topic_accuracies_testing = {}\n",
        "topic_accuracies_training = {}\n",
        "\n",
        "# for each topic, train (i.e. \"fit\") and classify (\"predict\") and evaulate\n",
        "print(f'For each topic, the model is: training, predicting, and evaluating.')\n",
        "# for topic in tqdm(top_topics_list):\n",
        "for topic in top_topics_list:\n",
        "    \n",
        "    # train the model \n",
        "    pipeline.fit(X_train, train[topic])\n",
        "\n",
        "    # make predictions\n",
        "    prediction_training = pipeline.predict(X_train)\n",
        "    prediction_testing = pipeline.predict(X_test)\n",
        "\n",
        "    for i in range(test.shape[0]):\n",
        "        if prediction_testing[i] != 0:\n",
        "\n",
        "    # for i in range(train.shape[0]):\n",
        "    #     if prediction_training[i] != 0:\n",
        "\n",
        "            print(f\"{topic} --> for test item #{i}!\")\n",
        "            # continue\n",
        "\n",
        "    # print(prediction_testing[test_index].shape)\n",
        "    # print(type(prediction_testing))\n",
        "    # print()\n",
        "    # my_prediction = pipeline.predict(X_test[test_index:test_index+1])\n",
        "\n",
        "    # evaluate and record performance\n",
        "    train_accuracy = accuracy_score(train[topic], prediction_training)\n",
        "    topic_accuracies_training[topic] = round(train_accuracy,3)\n",
        "    \n",
        "    test_accuracy = accuracy_score(test[topic], prediction_testing)\n",
        "    topic_accuracies_testing[topic] = round(test_accuracy,3)\n",
        "\n",
        "# ranked_topic_accuracies = \n",
        "for topic in top_topics_list:\n",
        "# for topic, accuracy in topic_accuracies.items():\n",
        "    # if True:\n",
        "    if False:\n",
        "        print()\n",
        "        print(topic)\n",
        "        print(topic_accuracies_training[topic], '<--', \"train\")\n",
        "        print(topic_accuracies_testing[topic], '<--', \"test\")\n",
        "    continue\n",
        "\n",
        "\n",
        "\n",
        "selected_topics = []\n",
        "# selected_topics = [\"some topic\"]\n",
        "\n",
        "# selected_topics = [topic for topic in test.columns[4:] if test[:,topic] != 0]\n",
        "# for idx, selected_topic in enumerate(test.columns[:10]):\n",
        "\n",
        "for idx, selected_topic in enumerate(selected_topics):\n",
        "    print(idx, selected_topic)\n",
        "\n",
        "print(f\"\\nFinished at {datetime.now()} for {NUM_DATA_POINTS} rows and {NUM_TOPICS} topics!\")"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}